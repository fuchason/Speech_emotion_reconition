{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from dataset import Dataset, load_data, attention_init\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Masking, Dropout, LSTM, Bidirectional, Activation, Conv2D, Conv1D, MaxPool1D, AveragePooling1D, BatchNormalization\n",
    "from keras.layers.merge import dot\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 516\n",
    "features_number = 34\n",
    "hidden_unit = 512\n",
    "dropout_rate = 0.65\n",
    "lstm_cells = 128\n",
    "classes = 5\n",
    "batch = 64\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltfunction(acc,loss,name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "    epoch = range(len(acc))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.plot(epoch,acc,\"x-\",label=name+'acc')\n",
    "    plt.plot(epoch,loss, \"+-\", label=name+'loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=1)\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SER_mix_model(tra_data, tra_label, val_data, val_label, max_len,features_num, hidden_unit, dp_rate, lstm_cells, classes, epochs, batch_size):\n",
    "\n",
    "    u_train, u_val = attention_init(tra_data.shape[0], val_data.shape[0], 256, 1.0/256)\n",
    "    \n",
    "    with k.name_scope('globalCNN_BLSTMLayer'):\n",
    "        ipt_features = Input(shape=(max_len, features_num))\n",
    "        x = Conv1D(64,3,activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(ipt_features)\n",
    "        x = Conv1D(128,1,activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(x)\n",
    "        x = Conv1D(256,3,activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(x)\n",
    "        x = MaxPool1D(2,2)(x)\n",
    "        x = Conv1D(512,3,activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(ipt_features)\n",
    "        x = Conv1D(1024,1,activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(x)\n",
    "        x = Conv1D(2048,3,activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(x)\n",
    "        x = MaxPool1D(2,2)(x)\n",
    "        x = BatchNormalization(axis=-1, momentum=0.9)(x)\n",
    "#         x = Masking(mask_value=-100.0)(ipt_features)\n",
    "        x = Dense(hidden_unit, activation='relu',kernel_initializer='uniform',bias_initializer='zeros')(x)\n",
    "        x = Dropout(dp_rate)(x)\n",
    "#         x = Dense(hidden_unit, activation='relu')(ipt_features)\n",
    "#         x = Dropout(dp_rate)(x)\n",
    "        x = Bidirectional(LSTM(lstm_cells, return_sequences=True, dropout=dp_rate,kernel_initializer='uniform',bias_initializer='zeros'))(x)\n",
    "        y = Bidirectional(LSTM(lstm_cells, return_sequences=True, dropout=dp_rate,kernel_initializer='uniform',bias_initializer='zeros'))(x)\n",
    "    with k.name_scope('AttentionLayer'):\n",
    "        ipt_attention = Input(shape=(lstm_cells*2,))\n",
    "        u = Dense(lstm_cells*2, activation='softmax',kernel_initializer='uniform',bias_initializer='zeros')(ipt_attention)\n",
    "        alp = dot([u,y], axes=-1)\n",
    "        alp = Activation('softmax')(alp)\n",
    "    with k.name_scope('WeightPooling'):\n",
    "        z = dot([alp, y], axes=1) #utterance-level\n",
    "    \n",
    "    opt = Dense(classes, activation='softmax',kernel_initializer='uniform',bias_initializer='zeros')(z)\n",
    "    model = Model(inputs=[ipt_attention, ipt_features],outputs=opt)\n",
    "    model.summary()\n",
    "    optimizer = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "    file_path = 'weights_blstm_mix_5cla_val_lossbest2' + '.h5'\n",
    "    callback_list = [\n",
    "                    EarlyStopping(\n",
    "                        monitor='loss',\n",
    "                        patience=150,\n",
    "                        verbose=1,\n",
    "                        mode='auto'\n",
    "                    ),\n",
    "                    ModelCheckpoint(\n",
    "                        filepath=file_path,\n",
    "                        monitor='val_loss',\n",
    "                        save_best_only='True',\n",
    "                        verbose=1,\n",
    "                        mode='auto',\n",
    "                        period=1\n",
    "                    )\n",
    "                    ]\n",
    "\n",
    "    training = model.fit([u_train, tra_data], tra_label, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                             callbacks=callback_list, \n",
    "                             validation_data=([u_val,val_data], val_label))\n",
    "    history = training.history\n",
    "    acc = np.asarray(history['acc'])\n",
    "    loss = np.asarray(history['loss'])\n",
    "    pltfunction(acc,loss,\"training_mix\")\n",
    "    val_loss = np.asarray(history['val_loss'])\n",
    "    val_acc = np.asarray(history['val_acc'])\n",
    "    pltfunction(val_loss,val_acc,\"testing_mix\")\n",
    "\n",
    "    acc_and_loss = np.column_stack((acc, loss, val_acc, val_loss))\n",
    "    save_file_blstm = 'blstm_training_mix_5cla_val_lossbest2' + '.csv'\n",
    "    with open(save_file_blstm, 'wb'):\n",
    "        np.savetxt(save_file_blstm, acc_and_loss)\n",
    "    \n",
    "#     u_test, _ = attention_init(x_test.shape[0], x_test.shape[0], 256, 1.0/256)\n",
    "    score_test, accuracy_test = model.evaluate([u_val,val_data], val_label, batch_size=128, verbose=1)\n",
    "#     score_2, accuracy_2 = model.evaluate([u_val2,x_test2], y_test2, batch_size=128, verbose=1)\n",
    "    print('*******************************************************')\n",
    "    print(\"Final test validation accuracy: %s\" % accuracy_test)\n",
    "#     print(\"Final test2 validation accuracy: %s\" % accuracy_2)\n",
    "    print('*******************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 516, 34)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 514, 512)     52736       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 514, 1024)    525312      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 512, 2048)    6293504     conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 256, 2048)    0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 2048)    8192        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256, 512)     1049088     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256, 512)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256, 256)     656384      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 256, 256)     394240      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 256)          0           dense_2[0][0]                    \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 256)          0           activation_1[0][0]               \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            1285        dot_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 9,046,533\n",
      "Trainable params: 9,042,437\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (8360, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3c528f25a98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m m = SER_mix_model(tra_data=mix_tra_feature, tra_label=mix_tra_label, val_data=mix_val_data, val_label=mix_val_label,\n\u001b[1;32m      7\u001b[0m                   \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                   lstm_cells=lstm_cells, classes=classes, epochs=epochs, batch_size=batch)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b49d429265b3>\u001b[0m in \u001b[0;36mSER_mix_model\u001b[0;34m(tra_data, tra_label, val_data, val_label, max_len, features_num, hidden_unit, dp_rate, lstm_cells, classes, epochs, batch_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m     training = model.fit([u_train, tra_data], tra_label, batch_size=batch_size, epochs=epochs, verbose=1,\n\u001b[1;32m     57\u001b[0m                              \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                              validation_data=([u_val,val_data], val_label))\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (8360, 2)"
     ]
    }
   ],
   "source": [
    "mix_tra_label = np.asarray(pickle.load(open('tra_label_5cla_mix_labels_ActorDep.p', 'rb')))\n",
    "mix_tra_feature = np.asarray(pickle.load(open('tra_data_5cla_mix_features_ActorDep.p', 'rb')))\n",
    "mix_val_data=np.asarray(pickle.load(open('val_data_5cla_mix_features_ActorDep.p','rb')))\n",
    "mix_val_label=np.asarray(pickle.load(open('val_label_5cla_mix_labels_ActorDep.p','rb')))\n",
    "\n",
    "m = SER_mix_model(tra_data=mix_tra_feature, tra_label=mix_tra_label, val_data=mix_val_data, val_label=mix_val_label,\n",
    "                  max_len=max_len, features_num=features_number, hidden_unit=hidden_unit, dp_rate=dropout_rate,\n",
    "                  lstm_cells=lstm_cells, classes=classes, epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([-2.1289892e-05, -1.4010740e-06,  2.3305158e-06, ...,\n",
      "       -3.2377432e-06,  1.1344974e-06, -3.5677920e-07], dtype=float32)\n",
      "  16000]\n",
      " [array([ 2.2111117e-05,  3.8449856e-05,  3.2233750e-06, ...,\n",
      "       -5.4563716e-06, -2.9611267e-05, -1.5393754e-05], dtype=float32)\n",
      "  16000]\n",
      " [array([-1.3905451e-05,  1.8560990e-05, -2.4276007e-06, ...,\n",
      "        2.6607271e-05, -3.3781089e-05, -1.2083523e-05], dtype=float32)\n",
      "  16000]\n",
      " ...\n",
      " [array([ 0.0000000e+00, -4.2724609e-04, -6.4086914e-04, ...,\n",
      "       -9.1552734e-05, -9.1552734e-05, -9.1552734e-05], dtype=float32)\n",
      "  16000]\n",
      " [array([ 0.00076294,  0.00094604,  0.00112915, ..., -0.00054932,\n",
      "        0.00018311, -0.00018311], dtype=float32)\n",
      "  16000]\n",
      " [array([ 0.00222778,  0.00073242,  0.00048828, ..., -0.00595093,\n",
      "       -0.00570679, -0.00671387], dtype=float32)\n",
      "  16000]]\n"
     ]
    }
   ],
   "source": [
    "print(mix_tra_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
