{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from dataset import Dataset, load_data, attention_init\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Masking, Dropout, LSTM, Bidirectional, Activation, Conv2D, Conv1D, MaxPool1D, AveragePooling1D, BatchNormalization\n",
    "from keras.layers.merge import dot\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ger = 'berlin'\n",
    "dataset_ch = 'CASIA'\n",
    "max_len = 516\n",
    "features_number = 34\n",
    "hidden_unit = 512\n",
    "dropout_rate = 0.65\n",
    "lstm_cells = 128\n",
    "classes = 8\n",
    "batch = 64\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ger, features_ger = load_data(dataset_ger)\n",
    "DATA_ch, features_ch = load_data(dataset_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mix_data_labels.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e46590ee6e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmix_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mix_data_labels.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmix_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mix_data_features.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mix_data_labels.p'"
     ]
    }
   ],
   "source": [
    "mix_label = pickle.load(open('mix_data_labels.p', 'rb'))\n",
    "mix_feature = pickle.load(open('mix_data_features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(train_data, label_data, data_test1, label_test1, data_test2, label_test2, max_len,features_num, hidden_unit, dp_rate, lstm_cells, classes, epochs, batch_size):\n",
    "    label_test1 = to_categorical(label_test1, num_classes=classes)\n",
    "    label_test2 = to_categorical(label_test2, num_classes=classes)\n",
    "    label_data = to_categorical(label_data, num_classes=classes)\n",
    "    \n",
    "    tra_data, val_data, tra_label, val_lable = train_test_split(train_data, label_data, test_size=0.4, random_state=886)\n",
    "    \n",
    "#     x_test1, _, y_test1, _ = train_test_split(data_test1, label_test1, test_size=0, random_state=886)\n",
    "# #     _, x_test_Ch, _, y_test_Ch = train_test_split(data_test, label_test, test_size=1, random_state=886)\n",
    "#     x_test2, _, y_test2, _ = train_test_split(data_test2, label_test2, test_size=0, random_state=886)\n",
    "    x_test, val_data, y_label, val_label = train_test_split(val_data, val_lable, test_size=0.5, random_state=886)\n",
    "\n",
    "    u_train1, u_val1 = attention_init(data_test1.shape[0], label_test1.shape[0], 256, 1.0/256)\n",
    "    u_train2, u_val2 = attention_init(data_test2.shape[0], label_test2.shape[0], 256, 1.0/256)\n",
    "    u_test, _ = attention_init(x_test.shape[0], x_test.shape[0], 256, 1.0/256)\n",
    "    model_lossbest = load_model('./weights_blstm_mix_lossbest2.h5')\n",
    "    score_3, accuracy_3 = model.evaluate([u_train1,data_test1], label_test1, batch_size=128, verbose=1)\n",
    "    score_2, accuracy_2 = model.evaluate([u_train2,data_test2], label_test2, batch_size=128, verbose=1)\n",
    "    score_1, accuracy_1 = model.evaluate([u_test,x_test], y_label, batch_size=128, verbose=1)\n",
    "#     score_2, accuracy_2 = model.evaluate([u_val2,x_test2], y_test2, batch_size=128, verbose=1)\n",
    "    print('*******************************************************')\n",
    "    print(\"Final test validation accuracy: %s\" % accuracy_1)\n",
    "#     print(\"Final test2 validation accuracy: %s\" % accuracy_2)\n",
    "    print('*******************************************************')\n",
    "    print(\"Final german validation accuracy: %s\" % accuracy_3)\n",
    "    print('*******************************************************')\n",
    "    print(\"Final chinese validation accuracy: %s\" % accuracy_2)\n",
    "    print('*******************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(train_data=mix_feature, label_data=mix_label, data_test1=features_ger, label_test1=DATA_ger.targets, data_test2=features_ch, label_test2=DATA_ch.targets, max_len=max_len, features_num=features_number, hidden_unit=hidden_unit, dp_rate=dropout_rate,\n",
    "          lstm_cells=lstm_cells, classes=classes, epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(val_data, val_label, model_path):\n",
    "#     val_label = to_categorical(val_label, num_classes=classes)\n",
    "    \n",
    "#     x_test, val_data, y_label, val_label = train_test_split(data, label, test_size=0.3, random_state=886)\n",
    "\n",
    "    u_val, _ = attention_init(val_data.shape[0], val_data.shape[0], 256, 1.0/256)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    score, accuracy = model.evaluate([u_val,val_data], val_label, batch_size=128, verbose=1)\n",
    "\n",
    "    print('*******************************************************')\n",
    "    print(\"Final test validation accuracy: %s\" % accuracy)\n",
    "    print('*******************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ger_data=pickle.load(open('val_data_5cla_ger_features.p','rb'))\n",
    "ger_label=pickle.load(open('val_label_5cla_ger_labels.p','rb'))\n",
    "ita_data=pickle.load(open('val_data_5cla_ita_features.p','rb'))\n",
    "ita_label=pickle.load(open('val_label_5cla_ita_labels.p','rb'))\n",
    "mix_data=pickle.load(open('val_data_5cla_mix_features.p','rb'))\n",
    "mix_label=pickle.load(open('val_label_5cla_mix_labels.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 16ms/step\n",
      "*******************************************************\n",
      "Final test validation accuracy: 0.7560975551605225\n",
      "*******************************************************\n",
      "144/144 [==============================] - 2s 16ms/step\n",
      "*******************************************************\n",
      "Final test validation accuracy: 0.2777777777777778\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset, load_data, attention_init\n",
    "from keras.models import Model, load_model\n",
    "path_ger='./weights_blstm_mix_val_lossbest_ger_5cal.h5'\n",
    "path_ita='./weights_blstm_mix_val_lossbest_ita_5cal.h5'\n",
    "test_model(val_data=ger_data,val_label=ger_label,model_path=path_ger)\n",
    "test_model(val_data=ita_data,val_label=ita_label,model_path=path_ger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 2s 7ms/step\n",
      "*******************************************************\n",
      "Final test validation accuracy: 0.6966292132599077\n",
      "*******************************************************\n",
      "144/144 [==============================] - 2s 11ms/step\n",
      "*******************************************************\n",
      "Final test validation accuracy: 0.5972222222222222\n",
      "*******************************************************\n",
      "123/123 [==============================] - 1s 11ms/step\n",
      "*******************************************************\n",
      "Final test validation accuracy: 0.8130081295967102\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "path_mix='./weights_blstm_mix_5cla_val_lossbest2.h5'\n",
    "test_model(val_data=mix_data,val_label=mix_label,model_path=path_mix)\n",
    "test_model(val_data=ita_data,val_label=ita_label,model_path=path_mix)\n",
    "test_model(val_data=ger_data,val_label=ger_label,model_path=path_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_data=pickle.load(open('CASIA_features.p','rb'))\n",
    "ch_label=to_categorical(pickle.load(open('CASIA_db.p','rb')).targets,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step\n",
      "*******************************************************\n",
      "Final test validation accuracy: 0.19800000047683716\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "test_model(val_data=ch_data,val_label=ch_label,model_path=path_ger)\n",
    "test_model(val_data=ch_data,val_label=ch_label,model_path=path_ita)\n",
    "test_model(val_data=ch_data,val_label=ch_label,model_path=path_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
